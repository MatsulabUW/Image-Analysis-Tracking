{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c069a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import napari\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc1b61df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_c3_t0\n"
     ]
    }
   ],
   "source": [
    "channel = 3\n",
    "i = 0 \n",
    "print(f'df_c{channel}_t{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afabd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(number_of_files: int ,channel: int, file_path: str):\n",
    "    '''\n",
    "    The function takes in all pickle files of the dataframes returned from detection for each time frame \n",
    "    and combines them into a single large dataframe. The function is provided with a specific folder path where it\n",
    "    goes and extracts all the pickle files. \n",
    "    \n",
    "    Note: \n",
    "    The naming convention of the files is fixed to a specific naming convention. For example for channel 2 frame 0\n",
    "    the name of the file should be df_c2_t0. This must be followed for this function to work properly. \n",
    "    \n",
    "    Inputs: \n",
    "    1. number_of_files: type(int), This is equal to the number of time frames/files in the specified folder \n",
    "    2. file_path: type(int), the path of the folder where all the files for a specific channel is stored\n",
    "    3. channel: type(str), The channel number (e.g 1,2,3)\n",
    "    \n",
    "    Returns: \n",
    "    1. combined_df: type(Dataframe), this is a combined dataframe for all detections for a single channel \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07cbdd2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_files):\n\u001b[1;32m     12\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_c_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory_path, file_name)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Load the DataFrame from the pickle file\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(file_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the directory where your pickle files are located\n",
    "directory_path = '/Users/apple/Desktop/Akamatsu_Lab/pyLattice_tutorials/DataFrames/Channel_2_pkl/'\n",
    "\n",
    "# Number of files you want to access\n",
    "num_files = 130  # Adjust this as needed\n",
    "\n",
    "# Create an empty list to store the individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Load pickle files, add \"frame\" column, and store DataFrames\n",
    "for i in range(num_files):\n",
    "    file_name = f\"df_c{channel}_t{i}.pkl\"\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    \n",
    "    # Load the DataFrame from the pickle file\n",
    "    df = pd.read_pickle(file_path)\n",
    "    \n",
    "    # Extract the frame number from the file name\n",
    "    frame = int(file_name.split(\"_t\")[1].split(\".\")[0])\n",
    "    \n",
    "    # Add the \"frame\" column to the DataFrame\n",
    "    df[\"frame\"] = frame\n",
    "    \n",
    "    # Append the DataFrame to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate the list of DataFrames into a single larger DataFrame\n",
    "complete_df = pd.concat(dataframes, ignore_index=True)\n",
    "tracking_df = complete_df.drop(['sigma_x', 'sigma_y', 'sigma_z', 'amplitude'], axis = 1)\n",
    "tracking_df = tracking_df.loc[:, ['frame', 'mu_x', 'mu_y', 'mu_z']]\n",
    "# Now 'final_dataframe' contains all the data from the 10 frames with a \"frame\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23d728",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
