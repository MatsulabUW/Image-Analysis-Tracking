{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7699bd06-dc64-4aee-8802-d99882165dd1",
   "metadata": {},
   "source": [
    "# This is the first step in the pipeline\n",
    "### Spots are detected in this notebook. The input file is expected to be in the zarr format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a4feae-de71-474c-a3b1-9d442d2a2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import zarr\n",
    "import napari \n",
    "import dask.array as da \n",
    "\n",
    "pythonPackagePath = os.path.abspath('../src/')\n",
    "sys.path.append(pythonPackagePath)\n",
    "from parallel import Detector\n",
    "from gaussian_visualization import visualize_3D_gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdcb7e-0da4-4aee-a372-e2128ce2cfae",
   "metadata": {},
   "source": [
    "### Do not change the code in cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5690e846-bfa8-46ae-947f-64b537f09bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that your notebook is inside 'Jupyter Notebooks', which is at the same level as 'test_data'\n",
    "# base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'movie_data')\n",
    "base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'test_movie_1')\n",
    "\n",
    "zarr_directory = 'zarr_file/all_channels_data'\n",
    "zarr_full_path = os.path.join(base_dir, zarr_directory)\n",
    "\n",
    "save_directory = 'datasets'\n",
    "save_directory_full = os.path.join(base_dir, save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa8f87",
   "metadata": {},
   "source": [
    "## Follow the Instructions below to run through the notebook properly \n",
    "\n",
    "The purpose of this notebook is to perform spot detection on your full movie. The movie is expected to be a 3 channel movie which is saved as a zarr object. If your movie is not a zarr object you can convert it to a zarr object by running and following the steps provided to you under Final/Data Preparation/full_movie_to_zarr.ipynb\n",
    "\n",
    "**For Initialising the Detector Object** \n",
    "\n",
    "1. Detector object is the main object for which you will setup the parameters to work in this notebook. \n",
    "2. **zarr_obj**: is the object which efficiently stores the movie \n",
    "3. **save_directory**: is fixed and does not need to be changed. However, for reference the files from this notebook will be outputted and saved in Final/movie_data/datasets directory \n",
    "4. **spot_intensity**: This is the minimum intensity which a spot will have in your movie. Anything below this can be called noise/background. You can determine the spot_intensity using fiji or napari to determine minimum bright spots which are of interest. If you set a spot_intensity too high very few spots will be detected, however, if you set a intensity too low a lot of spots including a lot of noise will be detected. \n",
    "5. **dist_between_spots**: this distance divided by 2 is the minimum distance that should exist between spots in pixels. For example if you set this to 10 then all spots within 5 pixels of the center of your spot will be dropped(to understand which spot is dropped you can refer to the source code in the Final/src/gaussian_fitting.py file)\n",
    "6. **sigma_estimations**: This is the spread/radius of your spots from the center. It is entered in pixels and follows the order [z,y,x]. If you expect your spot to have a radius of 4 in z and 2 in x and y then you should enter [4,2,2]. To determine the spread/radius of your spot you can visualise in fiji and look at the metadata to understand the pixel radius. \n",
    "7. **n_jobs**: Detector class allows for parallel processing and the number of cores you want to use can be determined here. You can set it to -1 and it will use all_cores - 1 for processing. It is important to allow for parallel processing else for larger movies it will take a lot of time. \n",
    "8. **channel_to_detect**: The number of channel to detect. Convention is 1 for channel 1, 2 for channel 2 and 3 for channel 3. The detector object can only detect one channel at a time. \n",
    "\n",
    "**For running processing on frames** (run_parallel_frame_processing)\n",
    "\n",
    "1. **max_frames**: the maximum frames to process. This can be useful when you just want to test your parameters selected for the Detector object like spot_intensity, dist_between_spots and sigma_estimates. \n",
    "2. **all_frames**: If all frames is set to True then all frames are processed and the **max_frames** parameter is ignored. It is recommended to initially decide all the parameters on a subset of frames and then move onto this step as it may take a lot of time for larger movies. \n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "-> Cores to be utilized can be increased as available. Keep in mind that limitation can be posed by the RAM of your machine. As more cores are utilized more RAM is needed. \n",
    "\n",
    "-> Detection can be only performed on 1 channel at a time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec841e",
   "metadata": {},
   "source": [
    "## Set all parameters in the below cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e1565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refer to the above cell for explanation of each parameter \n",
    "spot_intensity = 180\n",
    "dist_between_spots = 10\n",
    "sigma_estimations = [4,2,2]\n",
    "n_jobs = -1\n",
    "channel_to_detect = 3 \n",
    "max_frames = 2 \n",
    "all_frames = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f8dc259-df31-401a-abd5-20a1e9c4e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the zarr file by adding file path in read mode\n",
    "z2 = zarr.open(zarr_full_path, mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69dbbf55-cf28-420a-866c-8168ac253834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"zarr-info\"><tbody><tr><th style=\"text-align: left\">Type</th><td style=\"text-align: left\">zarr.core.Array</td></tr><tr><th style=\"text-align: left\">Data type</th><td style=\"text-align: left\">uint16</td></tr><tr><th style=\"text-align: left\">Shape</th><td style=\"text-align: left\">(130, 3, 75, 150, 275)</td></tr><tr><th style=\"text-align: left\">Chunk shape</th><td style=\"text-align: left\">(1, 1, 75, 150, 275)</td></tr><tr><th style=\"text-align: left\">Order</th><td style=\"text-align: left\">C</td></tr><tr><th style=\"text-align: left\">Read-only</th><td style=\"text-align: left\">True</td></tr><tr><th style=\"text-align: left\">Compressor</th><td style=\"text-align: left\">Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)</td></tr><tr><th style=\"text-align: left\">Store type</th><td style=\"text-align: left\">zarr.storage.DirectoryStore</td></tr><tr><th style=\"text-align: left\">No. bytes</th><td style=\"text-align: left\">2413125000 (2.2G)</td></tr><tr><th style=\"text-align: left\">No. bytes stored</th><td style=\"text-align: left\">656696875 (626.3M)</td></tr><tr><th style=\"text-align: left\">Storage ratio</th><td style=\"text-align: left\">3.7</td></tr><tr><th style=\"text-align: left\">Chunks initialized</th><td style=\"text-align: left\">390/390</td></tr></tbody></table>"
      ],
      "text/plain": [
       "Type               : zarr.core.Array\n",
       "Data type          : uint16\n",
       "Shape              : (130, 3, 75, 150, 275)\n",
       "Chunk shape        : (1, 1, 75, 150, 275)\n",
       "Order              : C\n",
       "Read-only          : True\n",
       "Compressor         : Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0)\n",
       "Store type         : zarr.storage.DirectoryStore\n",
       "No. bytes          : 2413125000 (2.2G)\n",
       "No. bytes stored   : 656696875 (626.3M)\n",
       "Storage ratio      : 3.7\n",
       "Chunks initialized : 390/390"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b82bf1-0470-4214-802c-e77fa4ab330a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of frames are 130\n"
     ]
    }
   ],
   "source": [
    "frames = z2.shape[0]\n",
    "print(f'the number of frames are {frames}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9983d-8633-46d7-a59a-7885c93fbd1b",
   "metadata": {},
   "source": [
    "## In the below cell Detector object is initilized to perform detection. More details on the Detector object can be attained by the following line of code: \n",
    "**copy and paste in a new cell**\n",
    "\n",
    "?Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9a03bc8-4326-4fb0-87c0-d3af7eb67e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(zarr_obj = z2, \n",
    "                    save_directory = save_directory_full, \n",
    "                    spot_intensity = spot_intensity, \n",
    "                    dist_between_spots = dist_between_spots, \n",
    "                    sigma_estimations = sigma_estimations, n_jobs = n_jobs, channel_to_detect = channel_to_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763ea65-4a6c-4061-8e42-29e84012bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following function returns the dataframe and also saves it to the provided path in pkl format\n",
    "#set all_frames = True, to process all the time frames \n",
    "#max_frames is useful when you just want to perform detection on a subset of frames. \n",
    "#Note: when all_frames= True then max_frames is ignored \n",
    "df = detector.run_parallel_frame_processing(max_frames = max_frames, all_frames = all_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb5443-0c8f-41f3-9464-ba14e2bbf75c",
   "metadata": {},
   "source": [
    "# Visualising the Output\n",
    "## Labels are only for time frame 0, for all z slices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6b924",
   "metadata": {},
   "source": [
    "## Below you can see detected spots as masks on the original image and can adjust detection parameters if you think spots are not detected correctly \n",
    "\n",
    "### Once you are in the napari viewer you should adjust the contrast and the opacity to make sure both the masks and the raw movie is visible properly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efe3f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mask of the detections\n",
    "masks = visualize_3D_gaussians(zarr_obj = z2, gaussians_df = df)\n",
    "\n",
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "# importing the channel_to_detect\n",
    "detection_channel = dask_array[:,:,:,:,:]\n",
    "\n",
    "# which channel to show\n",
    "visibility_mask = [False, False, False]\n",
    "visibility_mask[channel_to_detect-1] = True\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# Can change the names of the channels as needed\n",
    "layer_raw = viewer.add_image(detection_channel, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], interpolation3d = 'nearest', blending = 'additive', colormap = 'magenta', visible = visibility_mask)\n",
    "# layer_raw = viewer.add_image(detection_channel, channel_axis = 1, name = ['detection channel'], interpolation3d = 'nearest', blending = 'additive', colormap = 'magenta')\n",
    "\n",
    "# layer_mask = viewer.add_image(masks, name = 'detections mask')\n",
    "layer_mask = viewer.add_image(masks, name = 'detections', interpolation3d = 'nearest', blending = 'additive', colormap = 'green')\n",
    "\n",
    "#other useful parameters \n",
    "#color_map = list\n",
    "#contrast_limits = list of list \n",
    "\n",
    "# Add Bounding Box\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0113030",
   "metadata": {},
   "source": [
    "If the detections don't line up well with the spots in the image:\n",
    "* make sure you are looking at the first time point\n",
    "* mouse over the spots in napari to get a sense for the intensity of the spots vs background - use the threshold distinguishing spots from background as spot_intensity \n",
    "* vary the dist_between_spots: if the detections are at a higher density than the visible spots, increase the dist_between_spots. And vice versa, if you see spots at a higher density than detections, lower the dist_between_spots.\n",
    "* If the detections are missing larger or smaller spots you can try increasing or decreasing the sigma_estimations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08adc4",
   "metadata": {},
   "source": [
    "# move to 02.filtering_spots for next steps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
