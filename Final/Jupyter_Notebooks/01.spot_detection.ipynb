{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65267fe5",
   "metadata": {},
   "source": [
    "# SPOTS DETECTOR\n",
    "## This notebook takes input of raw images(one channel at a time) and outputs spots for that channel over all frames in the image. For detailed analysis of a single frame use other notebooks in this folder.\n",
    "## Note \n",
    "1. The code to generate csv files as output has been commented out and can be used if needed \n",
    "2. Pickle files will be outputted to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d6315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "### package for 3d visualization\n",
    "#from itkwidgets import view                              \n",
    "#from aicssegmentation.core.visual import seg_fluo_side_by_side,  single_fluorescent_view, segmentation_quick_view\n",
    "#import skimage\n",
    "\n",
    "### local new python segmentation functions\n",
    "import os\n",
    "import sys\n",
    "pythonPackagePath = os.path.abspath('../src/')\n",
    "sys.path.append(pythonPackagePath)\n",
    "from peak_local_max_3d import peak_local_max_3d \n",
    "from gaussian_fitting import fit_multiple_gaussians\n",
    "from extract_data import extract_data_from_filename\n",
    "from gaussian_visualization import visualize_3D_gaussians\n",
    "from gaussian_fitting import check_fitting_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3904e160",
   "metadata": {},
   "source": [
    "## Change the following before running the code \n",
    "1. input_filename \n",
    "2. save_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805d5f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = '/Users/apple/Desktop/Akamatsu_Lab/pyLattice_tutorials/test_data/Channel3_complete.tif'\n",
    "\n",
    "# Specify the directory where you want to save the pickle files\n",
    "save_dir = '/Users/apple/Desktop/Akamatsu_Lab/pyLattice_tutorials/DataFrames/Channel_3_pkl'\n",
    "\n",
    "# csv saving directory \n",
    "#csv_save_dir = '../DataFrames/Channel_3_csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efa6210",
   "metadata": {},
   "source": [
    "## Change the following before running the code \n",
    "1. Intensity for Channel 2(set to 170) and for Channel 3(set to 180)\n",
    "2. Output Pickle File Name for channel 2 and channel 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a6039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 1, 75, 258, 275)\n",
      "(130, 75, 258, 275)\n",
      "frame number is 0\n",
      "local_maximas detected are 578\n",
      "10%(58 of 578)\n",
      "20%(116 of 578)\n",
      "30%(174 of 578)\n",
      "40%(232 of 578)\n",
      "50%(289 of 578)\n",
      "60%(347 of 578)\n",
      "70%(405 of 578)\n",
      "80%(463 of 578)\n",
      "90%(521 of 578)\n",
      "100%(578 of 578)\n",
      "frame number is 1\n",
      "local_maximas detected are 552\n",
      "10%(56 of 552)\n",
      "20%(111 of 552)\n",
      "30%(166 of 552)\n",
      "40%(221 of 552)\n",
      "50%(276 of 552)\n",
      "60%(332 of 552)\n",
      "70%(387 of 552)\n",
      "80%(442 of 552)\n",
      "90%(497 of 552)\n",
      "100%(552 of 552)\n",
      "frame number is 2\n",
      "local_maximas detected are 567\n",
      "10%(57 of 567)\n",
      "20%(114 of 567)\n",
      "30%(171 of 567)\n",
      "40%(227 of 567)\n",
      "50%(284 of 567)\n",
      "60%(341 of 567)\n",
      "70%(397 of 567)\n",
      "80%(454 of 567)\n",
      "90%(511 of 567)\n",
      "100%(567 of 567)\n",
      "frame number is 3\n",
      "local_maximas detected are 552\n",
      "10%(56 of 552)\n",
      "20%(111 of 552)\n",
      "30%(166 of 552)\n",
      "40%(221 of 552)\n",
      "50%(276 of 552)\n",
      "60%(332 of 552)\n",
      "70%(387 of 552)\n",
      "80%(442 of 552)\n",
      "90%(497 of 552)\n",
      "100%(552 of 552)\n",
      "frame number is 4\n",
      "local_maximas detected are 544\n",
      "10%(55 of 544)\n",
      "20%(109 of 544)\n",
      "30%(164 of 544)\n",
      "40%(218 of 544)\n",
      "50%(272 of 544)\n",
      "60%(327 of 544)\n",
      "70%(381 of 544)\n",
      "80%(436 of 544)\n",
      "90%(490 of 544)\n",
      "100%(544 of 544)\n",
      "frame number is 5\n",
      "local_maximas detected are 558\n",
      "10%(56 of 558)\n",
      "20%(112 of 558)\n",
      "30%(168 of 558)\n",
      "40%(224 of 558)\n",
      "50%(279 of 558)\n",
      "60%(335 of 558)\n",
      "70%(391 of 558)\n",
      "80%(447 of 558)\n",
      "90%(503 of 558)\n",
      "100%(558 of 558)\n",
      "frame number is 6\n",
      "local_maximas detected are 542\n",
      "10%(55 of 542)\n",
      "20%(109 of 542)\n",
      "30%(163 of 542)\n",
      "40%(217 of 542)\n",
      "50%(271 of 542)\n",
      "60%(326 of 542)\n",
      "70%(380 of 542)\n",
      "80%(434 of 542)\n",
      "90%(488 of 542)\n",
      "100%(542 of 542)\n",
      "the gaussian did not fit\n",
      "frame number is 7\n",
      "local_maximas detected are 544\n",
      "10%(55 of 544)\n",
      "20%(109 of 544)\n",
      "30%(164 of 544)\n",
      "40%(218 of 544)\n",
      "50%(272 of 544)\n",
      "60%(327 of 544)\n",
      "70%(381 of 544)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#original image shape is (t,z,y,x)\n",
    "image_raw = extract_data_from_filename(input_filename)\n",
    "#print(image_raw.shape)\n",
    "\n",
    "#transpose the image such that we get (t,z,x,y)\n",
    "image_raw = np.transpose(image_raw, axes =(0,1,3,2))\n",
    "\n",
    "#get the number of frames for our original data for automated analysis for all frames \n",
    "frames = image_raw.shape[0]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for frame in range(frames):\n",
    "    \n",
    "    print('frame number is', frame)\n",
    "    \n",
    "    single_frame_input = image_raw[frame]\n",
    "\n",
    "    #define threshold: a value(intensity) for the pixel below which all values would be considered noise and dropped \n",
    "    #define min_distance: min_distance/2 is the radius within which we will keep the peak with max value/intensity or \n",
    "    #if two peaks have the same value they will be kept \n",
    "    maximas = peak_local_max_3d(single_frame_input,min_distance=10,threshold=180)\n",
    "    print('local_maximas detected are', maximas.shape[0])\n",
    "\n",
    "\n",
    "    #give the expected std dev/radius of our particles for x,y,z \n",
    "    sigmaExpected_x__pixels = 2\n",
    "    sigmaExpected_y__pixels = 2\n",
    "    sigmaExpected_z__pixels = 4\n",
    "\n",
    "    sigmas_guesses = []\n",
    "    for i in range(len(maximas)):\n",
    "        sigmas_guesses.append([sigmaExpected_z__pixels,sigmaExpected_x__pixels,sigmaExpected_y__pixels])\n",
    "        \n",
    "    #last parameter in the fit_multiple_gaussians is similar to min_distance above, we should give half of the \n",
    "    #value here of min_distance   \n",
    "    gaussians, gaussians_popt = fit_multiple_gaussians(single_frame_input,maximas,sigmas_guesses,5)\n",
    "        \n",
    "    accumulator = []\n",
    "    for gaussian in gaussians:\n",
    "\n",
    "        if(gaussian!=-1):\n",
    "            amplitude = gaussian[0]\n",
    "\n",
    "            #print(gaussian)\n",
    "            mu_x     = int(gaussian[1][1]) ##this is going to be mu_z, previous code [1][0]\n",
    "            mu_y     = int(gaussian[1][2]) ##need to finalise what this is (x or y) [1][1]\n",
    "            mu_z     = int(gaussian[1][0]) ##need to finalise what this is (x or y) [1][2]\n",
    "            ##sigmas will also change due to the above \n",
    "            sigma_x  = int(gaussian[2][1]) \n",
    "            sigma_y  = int(gaussian[2][2])\n",
    "            sigma_z  = int(gaussian[2][0])\n",
    "            accumulator.append(np.array([amplitude,mu_x,mu_y,mu_z,sigma_x,sigma_y,sigma_z]))\n",
    "            \n",
    "    accumulator = np.array(accumulator)\n",
    "    df = pd.DataFrame()\n",
    "    df['amplitude'] = accumulator[:,0]\n",
    "    df['mu_x'] = accumulator[:,1]\n",
    "    df['mu_y'] = accumulator[:,2]\n",
    "    df['mu_z'] = accumulator[:,3]\n",
    "    df['sigma_x'] = accumulator[:,4]\n",
    "    df['sigma_y'] = accumulator[:,5]\n",
    "    df['sigma_z'] = accumulator[:,6]\n",
    "    df.head()\n",
    "    \n",
    "    error_list = check_fitting_error(single_frame_input,maximas,gaussians,sigmas_guesses)\n",
    "    \n",
    "    # Construct the filename\n",
    "    '''\n",
    "    filename_csv = f'df_c2_t{frame}.csv'\n",
    "    file_path_csv = os.path.join(csv_save_dir, filename_csv)\n",
    "    df.to_csv(file_path_csv)\n",
    "    '''\n",
    "\n",
    "    # Construct the filename based on the loop index (time_frame)\n",
    "    filename_pkl = f'df_c3_t{frame}.pkl'\n",
    "\n",
    "    # Construct the full file path by joining the directory and filename\n",
    "    file_path = os.path.join(save_dir, filename_pkl)\n",
    "\n",
    "    # Save the DataFrame to a pickle file with the specified path\n",
    "    df.to_pickle(file_path)\n",
    "end_time = time.time()\n",
    "\n",
    "print('time taken (seconds)', end_time - start_time)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6836498e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
